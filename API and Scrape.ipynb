{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95952cac",
   "metadata": {},
   "source": [
    "# ADS 509 Module 1: APIs and Web Scraping\n",
    "\n",
    "This notebook has two parts. In the first part, you will scrape lyrics from AZLyrics.com. In the second part, you'll run code that verifies the completeness of your data pull. \n",
    "\n",
    "For this assignment you have chosen two musical artists who have at least 20 songs with lyrics on AZLyrics.com. We start with pulling some information and analyzing them.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c8969e",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "185076b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "import re\n",
    "\n",
    "# for the lyrics scrape section\n",
    "import requests\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "from collections import defaultdict, Counter\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a47e2d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this cell for any import statements you add\n",
    "\n",
    "import shutil\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c13af3",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Lyrics Scrape\n",
    "\n",
    "This section asks you to pull data by scraping www.AZLyrics.com. In the notebooks where you do that work you are asked to store the data in specific ways. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5bd7df77",
   "metadata": {},
   "outputs": [],
   "source": [
    "artists = {'lildicky':\"https://www.azlyrics.com/l/lildicky.html\",\n",
    "           'lilwayne':\"https://www.azlyrics.com/l/lilwayne.html\"} \n",
    "# we'll use this dictionary to hold both the artist name and the link on AZlyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02a55388",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lildicky': 'https://www.azlyrics.com/l/lildicky.html',\n",
       " 'lilwayne': 'https://www.azlyrics.com/l/lilwayne.html'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artists"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c236c99b",
   "metadata": {},
   "source": [
    "## A Note on Rate Limiting\n",
    "\n",
    "The lyrics site, www.azlyrics.com, does not have an explicit maximum on number of requests in any one time, but in our testing it appears that too many requests in too short a time will cause the site to stop returning lyrics pages. (Entertainingly, the page that gets returned seems to only have the song title to [a Tom Jones song](https://www.azlyrics.com/lyrics/tomjones/itsnotunusual.html).) \n",
    "\n",
    "Whenever you call `requests.get` to retrieve a page, put a `time.sleep(5 + 10*random.random())` on the next line. This will help you not to get blocked. If you _do_ get blocked, which you can identify if the returned pages are not correct, just request a lyrics page through your browser. You'll be asked to perform a CAPTCHA and then your requests should start working again. \n",
    "\n",
    "## Part 1: Finding Links to Songs Lyrics\n",
    "\n",
    "That general artist page has a list of all songs for that artist with links to the individual song pages. \n",
    "\n",
    "Q: Take a look at the `robots.txt` page on www.azlyrics.com. (You can read more about these pages [here](https://developers.google.com/search/docs/advanced/robots/intro).) Is the scraping we are about to do allowed or disallowed by this page? How do you know? \n",
    "\n",
    "A: It is allowed because under user 008 (which is used to describe web crawlers) nothing is disallowed. In other words, web crawlers can scrape anything from the site.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac9d31ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's set up a dictionary of lists to hold our links\n",
    "lyrics_pages = defaultdict(list)\n",
    "urls = []\n",
    "\n",
    "for artist, artist_page in artists.items() :\n",
    "    r = requests.get(artist_page)\n",
    "    time.sleep(5 + 10*random.random())\n",
    "    soup = BeautifulSoup(r.text, 'html.parser')\n",
    "    links = soup.find_all('a', href=True)\n",
    "    for link in links:\n",
    "        if '/lyrics/lil' in link['href']:\n",
    "            urls.append(link.get('href'))\n",
    "            lyrics_pages[artist].append(link.get('href'))\n",
    "\n",
    "\n",
    "    # now extract the links to lyrics pages from this page\n",
    "    # store the links `lyrics_pages` where the key is the artist and the\n",
    "    # value is a list of links. \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c285ec1",
   "metadata": {},
   "source": [
    "Let's make sure we have enough lyrics pages to scrape. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae4cda68",
   "metadata": {},
   "outputs": [],
   "source": [
    "for artist, lp in lyrics_pages.items() :\n",
    "    assert(len(set(lp)) > 20) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "edca10d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For lildicky we have 82.\n",
      "The full pull will take for this artist will take 0.23 hours.\n",
      "For lilwayne we have 742.\n",
      "The full pull will take for this artist will take 2.06 hours.\n"
     ]
    }
   ],
   "source": [
    "# Let's see how long it's going to take to pull these lyrics \n",
    "# if we're waiting `5 + 10*random.random()` seconds \n",
    "for artist, links in lyrics_pages.items() : \n",
    "    print(f\"For {artist} we have {len(links)}.\")\n",
    "    print(f\"The full pull will take for this artist will take {round(len(links)*10/3600,2)} hours.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011be6c6",
   "metadata": {},
   "source": [
    "## Part 2: Pulling Lyrics\n",
    "\n",
    "Now that we have the links to our lyrics pages, let's go scrape them! Here are the steps for this part. \n",
    "\n",
    "1. Create an empty folder in our repo called \"lyrics\". \n",
    "1. Iterate over the artists in `lyrics_pages`. \n",
    "1. Create a subfolder in lyrics with the artist's name. For instance, if the artist was Cher you'd have `lyrics/cher/` in your repo.\n",
    "1. Iterate over the pages. \n",
    "1. Request the page and extract the lyrics from the returned HTML file using BeautifulSoup.\n",
    "1. Use the function below, `generate_filename_from_url`, to create a filename based on the lyrics page, then write the lyrics to a text file with that name. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "67693711",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_filename_from_link(link) :\n",
    "    \n",
    "    if not link :\n",
    "        return None\n",
    "    \n",
    "    # drop the http or https and the html\n",
    "    name = link.replace(\"https\",\"\").replace(\"http\",\"\")\n",
    "    name = link.replace(\".html\",\"\")\n",
    "\n",
    "    name = name.replace(\"/lyrics/\",\"\")\n",
    "    \n",
    "    # Replace useless chareacters with UNDERSCORE\n",
    "    name = name.replace(\"://\",\"\").replace(\".\",\"_\").replace(\"/\",\"_\")\n",
    "    \n",
    "    # tack on .txt\n",
    "    name = name + \".txt\"\n",
    "    \n",
    "    return(name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "94a78c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the lyrics folder here. If you'd like to practice your programming, add functionality \n",
    "# that checks to see if the folder exists. If it does, then use shutil.rmtree to remove it and create a new one.\n",
    "\n",
    "if os.path.isdir(\"lyrics\") : \n",
    "    shutil.rmtree(\"lyrics/\")\n",
    "\n",
    "os.mkdir(\"lyrics\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "44bc6e98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"[Hook: Lil Dicky]\\nAnd y'ain't even want it with da boy\\nCause the way I'm livin life, is a muthafuckin joy\\nOn some grown man B.I.\\nI could have been a girl\\nOr any ethnicity up in the world\\nBut I'm rollin with the top back\\nI ain't gotta worry where the cops at\\nI ain't gotta wear a fucking bra strap\\nMe and the crew\\nAre really doing everything that we like to\\nMan it's a damn good day to be a white dude\\n[Verse 1: Lil Dicky]\\nShit, I'm living good up in this bitch\\nDicky rollin round the city, blowin good up in that wip\\nI ain't black or Dominican, not Hispanic or Indian\\nSo imprisonment is not a predicament, I envision\\nFor a white boy\\nHollatcha muthafuckin kike, boy\\nHigher than a muthafuckin kite, it's iight boi\\nThey ain't suspicious of jews\\nI'll show contrition it's cool\\nSlap on the wrist, get ma daddy to choose\\nOne of them top lawyers dat be rollin round in his crew\\nI'm eating chop soy and bowlin on a carnival cruise\\nDas what I do kid\\nHappy that my name ain't stupid\\nDave coulda been Daquan with a few kids\\nBut now I'm farting, overeating at meals,\\nIf ain't I gotta theme party, Ion't be at goodwill\\nI'm dentist paying, tennis playing, smellin on some cabernet\\nAnd I ain't gay but if I was, everything would be okay, look...\\nI know I'm being condescending in ma rhymes\\nBut ma premium channels mean tyler perry's never live\\nGetting tickets, they sick, I sit at the eagle 45\\nWhere I'm eating when I'm high's where they eat at to survive (food chainssss)\\n[Hook]\\n[Verse 2: Lil Dicky]\\nYeah. It's little DI in this bitch ho\\nHappy that I'm white, but relieved I ain't a chick yo\\nI never wake up and have to cake on ma make up\\nOr straighten hair, I ain't given a damn\\nI'm wearing whatever I wanna in this muthafucka\\nThey up in heels\\nAnd tummy tuckin, theyon't grub except for takin them pills, foreal...\\nAnd ion't bleach shit\\nIon't gotta eat dick\\nI ain't bleeding up out ma penis\\nSmoking the weed, ion't fall asleep because I'm cheefing\\nIn disagreements, I participate without weeping\\nAnd when I'm freaking, I'm getting daps, high fives, and all that\\nMa rep goin up, and at best, ho a slut\\nSo what up\\nYa boy cut up\\nBut eat butter\\nAnd I ain't gotta speak to ma mother... to still love her\\nAnd I been getting better looking with age\\nBut a guy can get who he deserves with a horrible face\\nSeal interlude\\nI go on dates, and never have to worry bout getting raped\\nAnd I watch a game and never have to worry bout how it's played\\nAnd I meet a babe and never have to act deliriously fake\\nAnd if impregnate I can pack a back and be on my way, but good luck girl!\\n[Hook]\\n[Outro: Lil Dicky]\\nYeah... I'm happy as fuck man\\nFirst off I'm a dude so\\nThere was a one in two chance of that sucking\\nBut now I can run a seven minute mile\\nI can defend my self adequately\\nI can be logical\\nI can get along with my room-mates\\nWatch serious movies without being scared by them\\nAnd the on top of that I'm white\\nWhich is like, amazing because\\nEverybody naturally assumes I'm a great person\\nI get a fair shot at the life I deserve\\nI mean I could underachieve my way into any college in the country\\nI get my hair cut at a salon\\nPeople hold the door open for me which is nice\\nEr, I never have to get into a fight, like, for social purposes\\nAnd please don't take this as me just disparaging black people\\nIt ain't about that\\nIt's about me being happy that I'm white, know what I'm saying?\\nBut on that note, could someone explain to me why Fat Joe, and any other person of Hispanic descent, is allowed to say the N-word\\nI mean I guess it's unrelated but like that shit don't make any sense\\nI've been thinking about that shit a lot\\nBecause like if I could say the N-word, it would really help my rhyme scheme out\\nIt's like the perfect filler word\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup = BeautifulSoup(requests.get(\"https://www.azlyrics.com/lyrics/lildicky/whitedude.html\").content, \"html.parser\")\n",
    "soup.select_one(\".ringtone ~ div\").get_text(\n",
    "        strip=True, separator=\"\\n\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "29b2605a",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"/Users/halledavis/Desktop/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6d99732f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for artist in lyrics_pages :\n",
    "    artistfolder = \"lyrics/\"+artist\n",
    "    if os.path.isdir(artistfolder) : \n",
    "        shutil.rmtree(artistfolder)\n",
    "    os.mkdir(artistfolder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "26ddf476",
   "metadata": {},
   "outputs": [],
   "source": [
    "subs = 'lildicky'\n",
    "lildickyurls = list(filter(lambda x: subs in x, urls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d655b687",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_stub = \"https://www.azlyrics.com\" \n",
    "start = time.time()\n",
    "\n",
    "total_pages = 0 \n",
    "\n",
    "os.chdir(\"/Users/halledavis/Desktop/lyrics/lildicky\")\n",
    "\n",
    "path = os.getcwd()\n",
    "\n",
    "for x in lildickyurls :\n",
    "    if total_pages == 22:\n",
    "        break\n",
    "    name0 = x.replace('/', '')\n",
    "    name = name0.replace('.html', '')\n",
    "    filename = name+\".txt\"\n",
    "    if os.path.exists(filename):\n",
    "        file = open(filename, \"r+\")\n",
    "    else:\n",
    "        file = open(filename, \"w+\")\n",
    "    soup = BeautifulSoup(requests.get(url_stub+x).content, \"html.parser\")\n",
    "    time.sleep(5 + 10*random.random())\n",
    "    lyrics = soup.select_one(\".ringtone ~ div\").get_text(strip=True, separator=\"\\n\")\n",
    "    title = name.replace('lyricslildicky', '')\n",
    "    file.writelines(title+'\\n'+'\\n'+lyrics)\n",
    "    time.sleep(5 + 10*random.random())\n",
    "    total_pages += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "83cb0b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "subs = 'lilwayne'\n",
    "lilwayneurls = list(filter(lambda x: subs in x, urls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d98e805f",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_stub = \"https://www.azlyrics.com\" \n",
    "\n",
    "total_pages = 0 \n",
    "\n",
    "os.chdir(\"/Users/halledavis/Desktop/lyrics/lilwayne\")\n",
    "\n",
    "path = os.getcwd()\n",
    "\n",
    "for x in lilwayneurls :\n",
    "    if total_pages == 22:\n",
    "        break\n",
    "    name0 = x.replace('/', '')\n",
    "    name = name0.replace('.html', '')\n",
    "    filename = name+\".txt\"\n",
    "    if os.path.exists(filename):\n",
    "        file = open(filename, \"a+\")\n",
    "    else:\n",
    "        file = open(filename, \"w+\")\n",
    "    soup = BeautifulSoup(requests.get(url_stub+x).content, \"html.parser\")\n",
    "    time.sleep(5 + 10*random.random())\n",
    "    lyrics = soup.select_one(\".ringtone ~ div\").get_text(strip=True, separator=\"\\n\")\n",
    "    title = name.replace('lyricslilwayne', '')\n",
    "    file.writelines(title+'\\n'+'\\n'+lyrics)\n",
    "    time.sleep(5 + 10*random.random())\n",
    "    total_pages += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "87660747",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Use this space to carry out the following steps: \n",
    "    \n",
    "    # 1. Build a subfolder for the artist\n",
    "    # 2. Iterate over the lyrics pages\n",
    "    # 3. Request the lyrics page. \n",
    "        # Don't forget to add a line like `time.sleep(5 + 10*random.random())`\n",
    "        # to sleep after making the request\n",
    "    # 4. Extract the title and lyrics from the page.\n",
    "    # 5. Write out the title, two returns ('\\n'), and the lyrics. Use `generate_filename_from_url`\n",
    "    #    to generate the filename. \n",
    "    \n",
    "    # Remember to pull at least 20 songs per artist. It may be fun to pull all the songs for the artist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "36c394f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total run time was 0.24 hours.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total run time was {round((time.time() - start)/3600,2)} hours.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "054cf14b",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Evaluation\n",
    "\n",
    "This assignment asks you to pull data by scraping www.AZLyrics.com.  After you have finished the above sections , run all the cells in this notebook. Print this to PDF and submit it, per the instructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "217c2b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple word extractor from Peter Norvig: https://norvig.com/spell-correct.html\n",
    "def words(text): \n",
    "    return re.findall(r'\\w+', text.lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37778a1c",
   "metadata": {},
   "source": [
    "## Checking Lyrics \n",
    "\n",
    "The output from your lyrics scrape should be stored in files located in this path from the directory:\n",
    "`/lyrics/[Artist Name]/[filename from URL]`. This code summarizes the information at a high level to help the instructor evaluate your work. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bccac29c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For lildicky we have 22 files.\n",
      "For lildicky we have roughly 14667 words, 2753 are unique.\n",
      "For lilwayne we have 22 files.\n",
      "For lilwayne we have roughly 16840 words, 2054 are unique.\n"
     ]
    }
   ],
   "source": [
    "os.chdir(\"/Users/halledavis/Desktop/\")\n",
    "artist_folders = os.listdir(\"lyrics/\")\n",
    "artist_folders = [f for f in artist_folders if os.path.isdir(\"lyrics/\" + f)]\n",
    "\n",
    "for artist in artist_folders : \n",
    "    artist_files = os.listdir(\"lyrics/\" + artist)\n",
    "    artist_files = [f for f in artist_files if 'txt' in f or 'csv' in f or 'tsv' in f]\n",
    "\n",
    "    print(f\"For {artist} we have {len(artist_files)} files.\")\n",
    "\n",
    "    artist_words = []\n",
    "\n",
    "    for f_name in artist_files : \n",
    "        with open(\"lyrics/\" + artist + \"/\" + f_name) as infile : \n",
    "            artist_words.extend(words(infile.read()))\n",
    "\n",
    "            \n",
    "    print(f\"For {artist} we have roughly {len(artist_words)} words, {len(set(artist_words))} are unique.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080a02ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
